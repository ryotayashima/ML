{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"IMBd_embeding.ipynb","version":"0.3.2","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"metadata":{"id":"FnwrZF5Ll4lr","colab_type":"code","colab":{}},"cell_type":"code","source":["from keras.layers import Activation, Dense, Flatten, Embedding\n","from keras.callbacks import EarlyStopping\n","from keras import preprocessing\n","from keras.models import Sequential\n","from keras import optimizers\n","from keras.datasets import imdb\n","\n","'''\n","サンプルデータ生成\n","'''\n","# 特徴量として考慮する単語の数\n","max_features = 10000\n","# max_features個の最も出現頻度の高い単語のうち、max_lenだけ残してテキストをカット\n","max_len = 2000\n","\n","(x_train, y_train), (x_test, y_test) = imdb.load_data(num_words=max_features)\n","\n","# 整数のリストを形状が(samples, max_len)のs次元テンソルに変換\n","x_train = preprocessing.sequence.pad_sequences(x_train, maxlen=max_len)\n","x_test = preprocessing.sequence.pad_sequences(x_test, maxlen=max_len)\n","\n","'''\n","モデルの生成\n","'''\n","model = Sequential()\n","# Embedding(入力データの最大インデックス+1, 分散ベクトルの次元数, 入力の系列長) -> (batch_size(none), 入力の系列長, 分散ベクトルの次元数)\n","model.add(Embedding(10000, 8, input_length=max_len))\n","model.add(Flatten())    # (batch_size(none), maxlen * 8)の二次元テンソルに変換\n","model.add(Dense(1, activation=\"sigmoid\"))\n","model.compile(\n","    optimizer=\"rmsprop\",\n","    loss=\"binary_crossentropy\",\n","    metrics=[\"acc\"]\n",")\n","# model.summary()\n"],"execution_count":0,"outputs":[]},{"metadata":{"id":"2wXBxkS0mDOQ","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":411},"outputId":"3e00b21b-1c4d-4545-ca13-ff7976fa1211","executionInfo":{"status":"ok","timestamp":1555242435834,"user_tz":-540,"elapsed":40856,"user":{"displayName":"トムー","photoUrl":"","userId":"01084465765645554068"}}},"cell_type":"code","source":["'''\n","学習\n","'''\n","early_stopping = EarlyStopping(monitor= \"val_loss\", patience= 10, verbose= 1)\n","\n","history = model.fit(\n","    x_train, y_train,\n","    epochs=10,\n","    batch_size=32,\n","    validation_split=0.2,\n","    callbacks = [early_stopping]\n",")\n"],"execution_count":16,"outputs":[{"output_type":"stream","text":["Train on 20000 samples, validate on 5000 samples\n","Epoch 1/10\n","20000/20000 [==============================] - 4s 217us/step - loss: 0.5586 - acc: 0.7248 - val_loss: 0.3651 - val_acc: 0.8538\n","Epoch 2/10\n","20000/20000 [==============================] - 4s 199us/step - loss: 0.2820 - acc: 0.8913 - val_loss: 0.2806 - val_acc: 0.8878\n","Epoch 3/10\n","20000/20000 [==============================] - 4s 199us/step - loss: 0.2154 - acc: 0.9167 - val_loss: 0.2684 - val_acc: 0.8920\n","Epoch 4/10\n","20000/20000 [==============================] - 4s 201us/step - loss: 0.1823 - acc: 0.9313 - val_loss: 0.2699 - val_acc: 0.8948\n","Epoch 5/10\n","20000/20000 [==============================] - 4s 197us/step - loss: 0.1606 - acc: 0.9406 - val_loss: 0.2750 - val_acc: 0.8936\n","Epoch 6/10\n","20000/20000 [==============================] - 4s 197us/step - loss: 0.1433 - acc: 0.9474 - val_loss: 0.2819 - val_acc: 0.8946\n","Epoch 7/10\n","20000/20000 [==============================] - 4s 199us/step - loss: 0.1271 - acc: 0.9543 - val_loss: 0.2931 - val_acc: 0.8932\n","Epoch 8/10\n","20000/20000 [==============================] - 4s 196us/step - loss: 0.1142 - acc: 0.9591 - val_loss: 0.3049 - val_acc: 0.8898\n","Epoch 9/10\n","20000/20000 [==============================] - 4s 194us/step - loss: 0.1019 - acc: 0.9642 - val_loss: 0.3192 - val_acc: 0.8896\n","Epoch 10/10\n","20000/20000 [==============================] - 4s 200us/step - loss: 0.0902 - acc: 0.9685 - val_loss: 0.3310 - val_acc: 0.8896\n"],"name":"stdout"}]}]}